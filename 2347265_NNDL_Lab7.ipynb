{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC1Ilc1oKrkD"
      },
      "source": [
        "##**Load and Explore the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_XK8Dk52v-k",
        "outputId": "51b38ebc-e0c5-4b19-e6ba-780439fd9b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/tgdivy/poetry-foundation-poems?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8.88M/8.88M [00:00<00:00, 75.3MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/tgdivy/poetry-foundation-poems/versions/1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import kagglehub\n",
        "\n",
        "#Download the dataset from Kaggle\n",
        "path = kagglehub.dataset_download(\"tgdivy/poetry-foundation-poems\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-xieSq82whz"
      },
      "outputs": [],
      "source": [
        "#Loading the dataset\n",
        "df = pd.read_csv(os.path.join(path, \"PoetryFoundationData.csv\"), nrows=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh4mUQsR2ymU",
        "outputId": "f64bf23e-efae-42cf-96fa-6804331cc08b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'Title', 'Poem', 'Poet', 'Tags', 'input'], dtype='object')\n",
            "[\" Objects Used to Prop Open a Window  ***  Dog bone, stapler, cribbage board, garlic press because this window is loose—lacks suction, lacks grip. Bungee cord, bootstrap, dog leash, leather belt because this window had sash cords. They frayed. They broke. Feather duster, thatch of straw, empty bottle of Elmer's glue because this window is loud—its hinges clack open, clack shut. Stuffed bear, baby blanket, single crib newel because this window is split. It's dividing in two. Velvet moss, sagebrush, willow branch, robin's wing because this window, it's pane-less. It's only a frame of air. \", ' The New Church  ***  The old cupola glinted above the clouds, shone among fir trees, but it took him an hour for the half mile all the way up the hill. As he trailed, the village passed him by, greeted him, asked about his health, but everybody hurried to catch the mass, left him leaning against fences, measuring the road with the walking stick he sculpted. He yearned for the day when the new church would be built—right across the road. Now it rises above the moon: saints in frescoes meet the eye, and only the rain has started to cut through the shingles on the roof of his empty house. The apple trees have taken over the sky, sequestered the gate, sidled over the porch. ', \" Look for Me  ***  Look for me under the hood of that old Chevrolet settled in weeds at the end of the pasture. I'm the radiator that spent its years bolted in front of an engine shoving me forward into the wind. Whatever was in me in those days has mostly leaked away, but my cap's still screwed on tight and I know the names of all these tattered moths and broken grasshoppers the rest of you've forgotten. \"]\n"
          ]
        }
      ],
      "source": [
        "#Cleaning the data\n",
        "df['Poem'] = df['Poem'].str.replace(r'\\s+', ' ', regex=True)\n",
        "df['Title'] = df['Title'].str.replace(r'\\s+', ' ', regex=True)\n",
        "df['input'] = df['Title'] + ' *** ' + df['Poem']\n",
        "\n",
        "#Exploring the columns\n",
        "print(df.columns)\n",
        "\n",
        "input_data = df['input'].values.tolist()\n",
        "\n",
        "#Printing a portion of the corpus to verify\n",
        "print(input_data[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d613WxED20fq",
        "outputId": "48409a1c-e4a7-42d3-e321-5788d2a82918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30216\n"
          ]
        }
      ],
      "source": [
        "#Data Preprocessing:\n",
        "\n",
        "#Importing the required libraries\n",
        "import re\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#Tokenizing the text(converting each word to a unique integer)\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(input_data)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5MUy_iu22f5"
      },
      "outputs": [],
      "source": [
        "#Creating input sequences using sequences of words\n",
        "input_sequences = []\n",
        "for line in input_data:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, min(len(token_list), 50)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "#Calculating max_sequence_len\n",
        "max_sequence_len = max(len(seq) for seq in input_sequences)\n",
        "\n",
        "#Padding sequences and create predictors and labels\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
        "predictors, label = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "label = to_categorical(label, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhfFo-ZO24Yj"
      },
      "outputs": [],
      "source": [
        "#Defining the batch size\n",
        "batch_size = 32\n",
        "\n",
        "#Generator function to yield batches of data\n",
        "def data_generator(predictors, labels):\n",
        "    dataset_size = len(predictors)\n",
        "    indices = np.arange(dataset_size)\n",
        "    np.random.shuffle(indices)\n",
        "    for idx in indices:\n",
        "        yield predictors[idx], labels[idx]\n",
        "\n",
        "#Creating a TensorFlow Dataset from the generator function\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: data_generator(predictors, label),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(predictors.shape[1],), dtype=tf.int32),\n",
        "        tf.TensorSpec(shape=(label.shape[1],), dtype=tf.float32)\n",
        "    )\n",
        ")\n",
        "\n",
        "#Shuffle and batch the dataset\n",
        "dataset = dataset.shuffle(buffer_size=10000).batch(batch_size).repeat()\n",
        "\n",
        "#Splitting the dataset into training and validation sets\n",
        "train_size = 100000\n",
        "val_size = 20000\n",
        "\n",
        "train_dataset = dataset.take(train_size // batch_size)\n",
        "val_dataset = dataset.skip(train_size // batch_size).take(val_size // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EilCaKiS26Xr"
      },
      "outputs": [],
      "source": [
        "#Importing the required libraries\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
        "import pickle\n",
        "\n",
        "#Defining the ModelCheckpoint callback\n",
        "checkpoint_path = \"model_checkpoint.keras\"\n",
        "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                      monitor='val_loss',\n",
        "                                      save_best_only=True,\n",
        "                                      mode='min',\n",
        "                                      verbose=1)\n",
        "\n",
        "#Defining EarlyStopping callback\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "HAUmt3BZ28Xw",
        "outputId": "a69ff0d3-3bb2-48e9-f471-61f0e7a2a698"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,510,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">60,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30216</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,051,816</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │       \u001b[38;5;34m1,510,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m60,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30216\u001b[0m)               │       \u001b[38;5;34m3,051,816\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,623,016</span> (17.64 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,623,016\u001b[0m (17.64 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,623,016</span> (17.64 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,623,016\u001b[0m (17.64 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#LSTM Model Development\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(total_words, 50))\n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.build(input_shape=(None, max_sequence_len))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjGSGxZ12-GZ",
        "outputId": "a855a6fa-67e0-45f7-ccfa-f7407bdd5796"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.0619 - loss: 7.7105\n",
            "Epoch 1: val_loss improved from inf to 6.78440, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 144ms/step - accuracy: 0.0619 - loss: 7.7104 - val_accuracy: 0.0739 - val_loss: 6.7844\n",
            "Epoch 2/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.0768 - loss: 6.7559\n",
            "Epoch 2: val_loss improved from 6.78440 to 6.16784, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 147ms/step - accuracy: 0.0768 - loss: 6.7558 - val_accuracy: 0.0955 - val_loss: 6.1678\n",
            "Epoch 3/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.0969 - loss: 6.2247\n",
            "Epoch 3: val_loss improved from 6.16784 to 5.53495, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 147ms/step - accuracy: 0.0969 - loss: 6.2247 - val_accuracy: 0.1254 - val_loss: 5.5350\n",
            "Epoch 4/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.1181 - loss: 5.6813\n",
            "Epoch 4: val_loss improved from 5.53495 to 4.92576, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 136ms/step - accuracy: 0.1181 - loss: 5.6813 - val_accuracy: 0.1689 - val_loss: 4.9258\n",
            "Epoch 5/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.1449 - loss: 5.1417\n",
            "Epoch 5: val_loss improved from 4.92576 to 4.31464, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 140ms/step - accuracy: 0.1449 - loss: 5.1417 - val_accuracy: 0.2390 - val_loss: 4.3146\n",
            "Epoch 6/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.1930 - loss: 4.6015\n",
            "Epoch 6: val_loss improved from 4.31464 to 3.76392, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 139ms/step - accuracy: 0.1930 - loss: 4.6015 - val_accuracy: 0.3142 - val_loss: 3.7639\n",
            "Epoch 7/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.2510 - loss: 4.0890\n",
            "Epoch 7: val_loss improved from 3.76392 to 3.26219, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 138ms/step - accuracy: 0.2510 - loss: 4.0889 - val_accuracy: 0.3997 - val_loss: 3.2622\n",
            "Epoch 8/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.3178 - loss: 3.6375\n",
            "Epoch 8: val_loss improved from 3.26219 to 2.81305, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 139ms/step - accuracy: 0.3178 - loss: 3.6375 - val_accuracy: 0.4701 - val_loss: 2.8131\n",
            "Epoch 9/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.3840 - loss: 3.2165\n",
            "Epoch 9: val_loss improved from 2.81305 to 2.42348, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 137ms/step - accuracy: 0.3840 - loss: 3.2165 - val_accuracy: 0.5424 - val_loss: 2.4235\n",
            "Epoch 10/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.4357 - loss: 2.8774\n",
            "Epoch 10: val_loss improved from 2.42348 to 2.13792, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 139ms/step - accuracy: 0.4357 - loss: 2.8774 - val_accuracy: 0.5922 - val_loss: 2.1379\n",
            "Epoch 11/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.4856 - loss: 2.5756\n",
            "Epoch 11: val_loss improved from 2.13792 to 1.86468, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 138ms/step - accuracy: 0.4856 - loss: 2.5756 - val_accuracy: 0.6398 - val_loss: 1.8647\n",
            "Epoch 12/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5301 - loss: 2.3203\n",
            "Epoch 12: val_loss improved from 1.86468 to 1.63006, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 139ms/step - accuracy: 0.5301 - loss: 2.3203 - val_accuracy: 0.6862 - val_loss: 1.6301\n",
            "Epoch 13/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5660 - loss: 2.1071\n",
            "Epoch 13: val_loss improved from 1.63006 to 1.45770, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 137ms/step - accuracy: 0.5660 - loss: 2.1071 - val_accuracy: 0.7182 - val_loss: 1.4577\n",
            "Epoch 14/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5996 - loss: 1.9188\n",
            "Epoch 14: val_loss improved from 1.45770 to 1.27363, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 145ms/step - accuracy: 0.5996 - loss: 1.9188 - val_accuracy: 0.7562 - val_loss: 1.2736\n",
            "Epoch 15/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.6249 - loss: 1.7664\n",
            "Epoch 15: val_loss improved from 1.27363 to 1.16026, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 136ms/step - accuracy: 0.6249 - loss: 1.7664 - val_accuracy: 0.7732 - val_loss: 1.1603\n",
            "Epoch 16/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.6493 - loss: 1.6279\n",
            "Epoch 16: val_loss improved from 1.16026 to 1.02380, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 138ms/step - accuracy: 0.6493 - loss: 1.6279 - val_accuracy: 0.8019 - val_loss: 1.0238\n",
            "Epoch 17/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.6702 - loss: 1.5119\n",
            "Epoch 17: val_loss improved from 1.02380 to 0.93769, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 136ms/step - accuracy: 0.6702 - loss: 1.5119 - val_accuracy: 0.8168 - val_loss: 0.9377\n",
            "Epoch 18/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.6925 - loss: 1.3961\n",
            "Epoch 18: val_loss improved from 0.93769 to 0.83774, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 141ms/step - accuracy: 0.6925 - loss: 1.3961 - val_accuracy: 0.8365 - val_loss: 0.8377\n",
            "Epoch 19/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.7064 - loss: 1.3126\n",
            "Epoch 19: val_loss improved from 0.83774 to 0.75521, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 138ms/step - accuracy: 0.7064 - loss: 1.3126 - val_accuracy: 0.8569 - val_loss: 0.7552\n",
            "Epoch 20/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.7236 - loss: 1.2368\n",
            "Epoch 20: val_loss improved from 0.75521 to 0.70181, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 137ms/step - accuracy: 0.7236 - loss: 1.2368 - val_accuracy: 0.8651 - val_loss: 0.7018\n",
            "Epoch 21/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.7354 - loss: 1.1636\n",
            "Epoch 21: val_loss improved from 0.70181 to 0.63957, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 147ms/step - accuracy: 0.7354 - loss: 1.1636 - val_accuracy: 0.8788 - val_loss: 0.6396\n",
            "Epoch 22/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.7459 - loss: 1.1024\n",
            "Epoch 22: val_loss improved from 0.63957 to 0.59993, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 141ms/step - accuracy: 0.7459 - loss: 1.1024 - val_accuracy: 0.8848 - val_loss: 0.5999\n",
            "Epoch 23/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.7575 - loss: 1.0437\n",
            "Epoch 23: val_loss improved from 0.59993 to 0.54606, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 140ms/step - accuracy: 0.7574 - loss: 1.0437 - val_accuracy: 0.8962 - val_loss: 0.5461\n",
            "Epoch 24/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.7647 - loss: 0.9988\n",
            "Epoch 24: val_loss improved from 0.54606 to 0.51458, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 146ms/step - accuracy: 0.7647 - loss: 0.9988 - val_accuracy: 0.9029 - val_loss: 0.5146\n",
            "Epoch 25/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7757 - loss: 0.9489\n",
            "Epoch 25: val_loss improved from 0.51458 to 0.47426, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 136ms/step - accuracy: 0.7757 - loss: 0.9489 - val_accuracy: 0.9102 - val_loss: 0.4743\n",
            "Epoch 26/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.7781 - loss: 0.9185\n",
            "Epoch 26: val_loss improved from 0.47426 to 0.43470, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 137ms/step - accuracy: 0.7781 - loss: 0.9185 - val_accuracy: 0.9187 - val_loss: 0.4347\n",
            "Epoch 27/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.7905 - loss: 0.8742\n",
            "Epoch 27: val_loss improved from 0.43470 to 0.40648, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 136ms/step - accuracy: 0.7905 - loss: 0.8742 - val_accuracy: 0.9250 - val_loss: 0.4065\n",
            "Epoch 28/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7963 - loss: 0.8388\n",
            "Epoch 28: val_loss improved from 0.40648 to 0.39086, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 133ms/step - accuracy: 0.7963 - loss: 0.8388 - val_accuracy: 0.9270 - val_loss: 0.3909\n",
            "Epoch 29/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8026 - loss: 0.8109\n",
            "Epoch 29: val_loss improved from 0.39086 to 0.35606, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 133ms/step - accuracy: 0.8026 - loss: 0.8109 - val_accuracy: 0.9338 - val_loss: 0.3561\n",
            "Epoch 30/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8058 - loss: 0.7925\n",
            "Epoch 30: val_loss improved from 0.35606 to 0.35128, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 133ms/step - accuracy: 0.8058 - loss: 0.7926 - val_accuracy: 0.9323 - val_loss: 0.3513\n"
          ]
        }
      ],
      "source": [
        "#Training the model with batching\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=30,\n",
        "                    verbose=1,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=[early_stopping_callback, checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tQZPY1Ny3Avy",
        "outputId": "5552b341-caac-4304-fac4-5e34410e525d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "#Saving the model\n",
        "model.save(\"trained_model.h5\")\n",
        "\n",
        "#Loading the trained model\n",
        "model = tf.keras.models.load_model('trained_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-tqYhcMT3DnV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37d25985-d640-461a-ca91-7ca1fa65f2df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated poetry with seed 'The sun':\n",
            "The sun has the species of tiny paper everywhere we have the angel is the platform and the race he had been\n",
            "\n",
            "Generated poetry with seed 'Love's embrace':\n",
            "Love's embrace summer after belly on one day my own harvest men never speak to us we spend the afternoon together watching\n",
            "\n",
            "Generated poetry with seed 'Autumn leaves':\n",
            "Autumn leaves this man is a new new twin daughters as not even all last names things always play your kiss me\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Text Generation\n",
        "\n",
        "def generate_poetry(seed_text, next_words, model, max_sequence_len, tokenizer):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "seed_texts = [\"The sun\", \"Love's embrace\", \"Autumn leaves\"]\n",
        "for seed_text in seed_texts:\n",
        "    generated_poetry = generate_poetry(seed_text, 20, model, max_sequence_len, tokenizer)\n",
        "    print(f\"Generated poetry with seed '{seed_text}':\\n{generated_poetry}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JRTMiMK73Fic",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "01520ab5-f280-492c-ea82-f9e73385e6f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │       \u001b[38;5;34m3,021,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │          \u001b[38;5;34m30,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m20,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30216\u001b[0m)               │       \u001b[38;5;34m1,541,016\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,021,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">30,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30216</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,541,016</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,613,016\u001b[0m (17.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,613,016</span> (17.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,613,016\u001b[0m (17.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,613,016</span> (17.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Evaluation and Experimentation:\n",
        "\n",
        "#Defining the LSTM model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(input_dim=vocab_size, output_dim=100))\n",
        "model2.add(LSTM(50, return_sequences=True))\n",
        "model2.add(LSTM(50))\n",
        "model2.add(Dropout(0.4))  #Dropout layer to prevent overfitting\n",
        "model2.add(Dense(vocab_size, activation='softmax'))  #Output layer for word prediction\n",
        "\n",
        "#Compiling the model\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2.build(input_shape=(None, max_sequence_len))\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SBqN1Ofc3Hdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57dd716a-1617-4dfb-8366-d65f461c3a70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated poetry with seed 'Whispers of night':\n",
            "Whispers of night after another lives in the end of the world we had a bowl to bring the past to the sea\n",
            "\n",
            "Generated poetry with seed 'A lone star':\n",
            "A lone star down on the lake the world of its empty through the house that keeps me down to the mountains of\n",
            "\n",
            "Generated poetry with seed 'In dreams we wander':\n",
            "In dreams we wander to come in your roses a head filled of course of my mind where did you speak on it came\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Lines of poetry that resemble the style of the training poems\n",
        "\n",
        "def generate_poetry(seed_text, next_words, model, max_sequence_len, tokenizer):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "seed_texts = [\"Whispers of night\", \"A lone star\", \"In dreams we wander\"]\n",
        "for seed_text in seed_texts:\n",
        "    generated_poetry = generate_poetry(seed_text, 20, model, max_sequence_len, tokenizer)\n",
        "    print(f\"Generated poetry with seed '{seed_text}':\\n{generated_poetry}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QxWGnt33P85"
      },
      "source": [
        "### Interpretation\n",
        "The code utilizes an LSTM model to generate new poetry lines by learning patterns and dependencies in a dataset of poems. It involves preparing the dataset, creating sequences, training an LSTM, and iteratively predicting the next word based on a seed text to generate new text. The goal is to produce text that has similar characteristics to the training data, like style and structure.\n",
        "\n",
        "By adjusting the model's parameters and experimenting with different seed texts, users can influence the creativity and fluency of the generated poetry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V4ABUvw3YVl"
      },
      "source": [
        "The generated poetry lines resemble the style and structure of the original dataset because the LSTM model has learned syntactic and thematic patterns from it. When each seed text is provided, the model uses it as a starting point and builds upon it, generating coherent lines that match the tone, rhythm, and sometimes even the sentiment of the original poems."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}